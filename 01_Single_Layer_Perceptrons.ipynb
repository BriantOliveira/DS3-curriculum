{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/ms_logo.jpeg' height=40% width=40%></center>\n",
    "\n",
    "<center><h1>Single Layer Perceptrons</h1></center>\n",
    "\n",
    "In our first notebook for this course, we'll begin by exploring the concept that started it all for neural networks: the **_Perceptron_**.  We start by exploring the the biological inspiration of the perceptron model to gain an intuition for how it works, and then we'll build one from scratch using python and numpy!\n",
    "\n",
    "\n",
    "<center><h3>What is a Perceptron?</h3></center>\n",
    "\n",
    "The **_Perceptron_** is a simple supervised learning algorithm used for binary classification. It was invented by psychologist and researcher Dr. Frank Rosenblatt in 1960.  Frank's goal was to study how the brain learned, and the perceptron was easily his most famous and most successful experiment.  By studying neurons in the brain, Dr. Rosenblatt realized he could use electronics to simulate what a neuron does, and more importantly, build a model that gets better with practice by \"learning\" from mistakes! \n",
    "\n",
    "Nowadays, the word \"perceptron\" refers to an algorithm.  However, the first perceptron was not a program but a fully functional machine consisting of wires, photocells, potentiometers, and a camera.  Dr. Rosenblatt called this machine the _Mark I Perceptron_, and the name stuck.  The machine was used for image classification, and is generally considered the forerunner to modern Artifical Intelligence.  The work done by Dr. Rosenblatt was considered so important that the IEEE gives out a prestigious [Frank Rosenblatt Award](https://www.ieee.org/about/awards/tfas/rosenblatt.html) for \"outstanding contributions to biologically and linguistically motivated computational paradigms and systems.\"\n",
    "\n",
    "<center><img src='img/perceptron.jpg'></center>\n",
    "<center>The Mark I Perceptron Machine</center>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center><h3>Neurons and Perceptrons</h3></center>\n",
    "\n",
    "To understand how perceptrons work, we'll first look at the biological structure that inspired it--the **_neuron_**!  The brain consists of special types of cells called neurons--the average human brain contains over 100 billion. Everything that you perceive, think, or do can be traced back to electrical impulses between connected neurons in your brain.  Neurons pass informaiton along by receiving electrical impulses from other neurons--if the sum of these incoming impulses is greater than the receiving neuron's **_activation threshold_**, a tipping point is reached and the neuron \"fires\", passing it's own electrical impulse along to other neurons it is connected to.  Importantly, these neurons only pass their messages in one direction--this is typically referred to as \"feed-forward\". They have an input side, and an output side.  \n",
    "\n",
    "<center><img src='img/neuron_diagram.jpg'></center>\n",
    "<center>Inputs enter through Dendrites on the left.  When the neuron fires, output travels through the Axon Terminals on the right.</center>\n",
    "\n",
    "<center><h3>Some Inputs Are Better Than Others</h3></center>\n",
    "\n",
    "In both perceptrons and neurons, an important distinction is that every neuron has different weights for the neurons passing it input.  This makes intuitive sense--when someone gives you good advice, you tend to listen to them more often, and allow their input to more heavily influence your decisions.  Alternatively, when someone gives you bad advice, it makes sense to give their advice less weight in future decisions (or, if they are consistently wrong, just do the opposite!).  This brings us to a more formal description of how perceptrons work:\n",
    "\n",
    "Perceptrons take in multiple inputs, which each have different weights assigned to them.  The perceptron computes the weighted sum of the inputs, and checks to see if this sum is greater than it's activation threshold.  If the sum is greater than or equal to the threshold, the perceptron fires (returns `True`)--otherwise, it does not fire (returns `False`).   \n",
    "\n",
    "If you've been paying attention, you've likely asked yourself a very important question--**_how do we pick good weights for each of our inputs?!_**  The answer is simpler than it may seem.  We could always just set the weights ourselves and leave them, but that isn't a good idea--what if we don't know what the weights should be?  It turns out, our best bet is to intialize them **_randomly_**, and then let them shift around as the perceptron **_learns the correct weights_** by looking at the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
